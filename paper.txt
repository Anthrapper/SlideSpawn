Face Recognition in Unconstrained Environments 
Abstract--This paper proposes a novel face recognition system having good recognition performance through elaborate face region detection in unconstrained illumination environments. The proposed system consists of face and eyes detection, rotated-angle compensation, face region cropping, preprocessing, and classification modules as sequential steps. In particular, the elaborate face region is obtained from automatic face cropping procedure based on distance information between the eyes. The performance evaluation was carried out with various pre- processing images on the Yale B and the CMU-PIE databases. From the experimental results, we confirmed that the proposed method showed the best recognition accuracy compared to different approaches. 
I. INTRODUCTION 
Face recognition has many applications such as biometrics systems, access control systems, surveillance systems, security systems, and content-based video retrieval systems [1]. Usually, face recognition systems can achieve good performance under controlled environments. However, face recognition tend to suffer when variations including illumination are presented in uncontrolled environments. Thus, this paper presents the novel face recognition system showing good performance through elaborate face region detection in unconstrained environments. 
II. PROPOSED SYSTEM 
This work has aimed to implement a novel face recognition system having good performance under unconstrained illumination environments. Generally, the most of traditional recognition approaches directly utilize a detected face image in the face recognition procedure. However, these approaches can be sometimes failed to recognize a user in practical environments, due to unelaborate detection of face region. To improve the face recognition performance on real environment, this paper proposes the novel face recognition system through elaborate face region detection. 
A. Region detection and preprocessing 
The first phase of proposed face recognition system is object detection including face and eyes region from the input image. To detect the face region, this paper employs the AdaBoost algorithm based on Haar-like features introduced by Viola and Jones [2]. After detecting the face and eyes region by using the AdaBoost algorithms based on Haar-like features (see Fig. 1 (a)), the coordinates of two eyes are utilized for rotated-angle compensation of the input image (see Fig. 1 (b)). In other words, the center coordinates of each eye can be obtained from the detection results, and we can calculate the rotated-angle with the horizontal line connecting both centers of eyes as show in Fig. 1 (a). The example of rotated image is also shown in Fig. 1 (b), and we can also know the converted center coordinates of both eyes on rotated image. Based on the center information of both eyes, we next compute the elaborate face region using image cropping as shown in Fig. 1 (c). Automatic image cropping of face region is done based on the distance, D, between two eyes. A distance between each eye and boundary is maintained as 0.4D. The height of the face region is set as 2.0D, here, the distance of from eye to bottom boundary is maintained as 1.5D. Finally, each face image was cropped by using boundary information and rescaled to a resolution of 60x54 pixels as shown 
To improve recognition performance on unconstrained illumination environments, we carry out the preprocessing procedure, in which preprocessing denotes that the binary pattern operators including local binary pattern (LBP) [3] and local directional pattern (LDP) [4] are applied in face image. The LBP operator labels the pixels of an image by thresholding a 3x3 neighborhood of each pixel with the center value. While the LBP operator uses the information of intensity changes around pixels, LDP operator use the edge response values of neighborhood pixels and encode the image texture. This pattern is calculated by comparing the relative edge response values of a pixel by using Kirsch edge detector. 
B. Classification 
Automatic detected and preprocessed face images are directly utilized as input images for facial feature extraction. In this work, we employ the well-known principal component analysis (PCA) [5] algorithm. PCA is a feature extraction and data representation technique widely used in the areas of pattern recognition, computer vision and signal processing. After feature extraction by PCA, nearest neighbor classifier based on the Euclidean distance is used to recognize an unknown face. 
III. EXPERIMENTAL RESULTS AND CONCLUSION 
To evaluate the recognition performance of the proposed method, we employed the images from the Yale B database and the CMU-PIE database. The Yale B database consists of 640 face images for 10 subjects representing 64 illumination conditions under the frontal pose. The CMU-PIE database contains 1,428 facial images of 21 illumination conditions for 68 individuals. First, we investigated the detection rates of two databases. Here, we only employed face images that were correctly detected the face and eyes regions from the input images in the experiments. In result, the detection rates revealed 91.71% and 94.57% for the Yale B and CMU-PIE databases, respectively. Fig. 2 showed an example of raw, histogram equalization, LBP, and LDP images for detected image and cropped image, respectively. Note that the cropped image (Group 2) are obtained from whole procedures including face and eyes detection, rotated-angle compensation, and image cropping, while the detected image (Group 1) denotes the face image obtained by the AdaBoost algorithms. The performance evaluation was carried out with each pre- processing image for each group. 
Next, we investigated the recognition performance of proposed system with two databases. To evaluate the recognition accuracy, we partitioned each database into training and testing sets. For the Yale B database, each training set comprised of seven images per subject, and the remaining images were used to test the proposed method. For the CMU- PIE database, three images from each person were also used for training and the remaining images were used for testing. For the Yale B database, the recognition results in terms of  different preprocessing images and groups were shown in Fig. 3, and the results of the CMU-PIE database were also depicted in Fig. 4. As a result, the proposed method using LDP and PCA on cropped images showed a best recognition rate of 91.56% and 85.80% for Yale B and CMU-PIE database, respectively. Consequently, we confirmed the effectiveness of the proposed method under unconstrained environments through the experimental results.